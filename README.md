NavAssist – Smart Navigation Aid for the Visually Impaired
NavAssist is a Flutter-based mobile application designed to empower visually impaired individuals with real-time object detection, audio feedback via Text-to-Speech (TTS), and GPS awareness for safer and smarter navigation.

🚀 Features
📷 Live Camera Feed – Simulated or real-time camera preview

🧠 Object Detection – Integrates TensorFlow Lite models for identifying surroundings

🔊 Text-to-Speech (TTS) – Converts detection results into spoken words for live guidance

📍 GPS Location Awareness – Accesses user's location to inform about surroundings (mocked or real)

🧪 Simple UI Buttons – Trigger actions like camera access, TTS playback, or GPS update manually

🎯 Purpose
This app was built during a hackathon to address the daily challenges faced by the visually impaired. By combining object recognition and audio alerts, NavAssist provides a basic yet powerful tool for environmental awareness.

🛠️ Tech Stack
Flutter – Frontend mobile app

TFLite – Lightweight model integration

Google ML Models (optional/custom) – For object detection

Flutter TTS Plugin – For audio feedback

Flutter Location Plugin – To access user location (optional or mocked)

Dart – Programming language used in Flutter

📷 UI Overview
Camera Button – Opens live feed from the phone camera

TTS Button – Speaks detected objects out loud

GPS Button – Fetches user location and gives verbal feedback

These features are connected to buttons on the home screen for demonstration and manual testing.
