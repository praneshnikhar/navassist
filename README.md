NavAssist â€“ Smart Navigation Aid for the Visually Impaired
NavAssist is a Flutter-based mobile application designed to empower visually impaired individuals with real-time object detection, audio feedback via Text-to-Speech (TTS), and GPS awareness for safer and smarter navigation.

ğŸš€ Features
ğŸ“· Live Camera Feed â€“ Simulated or real-time camera preview

ğŸ§  Object Detection â€“ Integrates TensorFlow Lite models for identifying surroundings

ğŸ”Š Text-to-Speech (TTS) â€“ Converts detection results into spoken words for live guidance

ğŸ“ GPS Location Awareness â€“ Accesses user's location to inform about surroundings (mocked or real)

ğŸ§ª Simple UI Buttons â€“ Trigger actions like camera access, TTS playback, or GPS update manually

ğŸ¯ Purpose
This app was built during a hackathon to address the daily challenges faced by the visually impaired. By combining object recognition and audio alerts, NavAssist provides a basic yet powerful tool for environmental awareness.

ğŸ› ï¸ Tech Stack
Flutter â€“ Frontend mobile app

TFLite â€“ Lightweight model integration

Google ML Models (optional/custom) â€“ For object detection

Flutter TTS Plugin â€“ For audio feedback

Flutter Location Plugin â€“ To access user location (optional or mocked)

Dart â€“ Programming language used in Flutter

ğŸ“· UI Overview
Camera Button â€“ Opens live feed from the phone camera

TTS Button â€“ Speaks detected objects out loud

GPS Button â€“ Fetches user location and gives verbal feedback

These features are connected to buttons on the home screen for demonstration and manual testing.
